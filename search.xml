<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>你好，欢迎光临我的博客</title>
    <url>/2020/04/30/%E4%BD%A0%E5%A5%BD%EF%BC%8C%E6%AC%A2%E8%BF%8E%E5%85%89%E4%B8%B4%E6%88%91%E7%9A%84%E5%8D%9A%E5%AE%A2%EF%BC%81/</url>
    <content><![CDATA[<h2 id="这篇说明将更好地帮助你在-lt-Mr-l’s-World-gt-里畅游"><a href="#这篇说明将更好地帮助你在-lt-Mr-l’s-World-gt-里畅游" class="headerlink" title="这篇说明将更好地帮助你在&lt;Mr.l’s World&gt;里畅游"></a>这篇说明将更好地帮助你在&lt;<em>Mr.l’s World</em>&gt;里畅游</h2><blockquote>
<p><strong>博客使用简介</strong></p>
</blockquote>
<ol>
<li><p>博客界面<strong>左侧</strong>有<strong>侧边菜单</strong>为你提供快捷帮助<strong>&lt;<em>手机用户请点击屏幕左上角按钮以呼出菜单</em>&gt;</strong></p>
</li>
<li><p>博客界面<strong>右下角</strong>有<strong>暗夜模式按钮</strong>为你提供更好的浏览体验</p>
</li>
<li><p>博客同样为你提供<strong>文章查找</strong>功能，功能按钮在<strong>侧边菜单</strong>的下方</p>
</li>
<li><p>博客已开放<strong>评论留言系统</strong>，欢迎大家在评论区留下你的足迹</p>
</li>
<li><p><strong>《语言之美-古诗丽词》</strong>与<strong>《语言之美-新句美文》</strong>两篇文章将不定时持续更新，欢迎大家在评论区留下自己的珍藏，我也很乐意将其收录进文章里面</p>
</li>
<li><p><strong>光影画廊</strong>模块里展示了一些我个人的绘画作品，希望大家能够喜欢(^^)</p>
</li>
</ol>
<blockquote>
<p>技术支持</p>
</blockquote>
<ul>
<li><strong>Powered by</strong> <a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo</a></li>
<li><strong>Theme:</strong> <a href="https://shen-yu.gitee.io/" target="_blank" rel="noopener">Ayer</a></li>
</ul>
<hr>
<p> (以下是博客更新日志，日志从2020/4/11开始记录，你<strong>可以点击</strong>&lt;阅读更多…&gt;来快速掌握博客更新动向)</p>
<a id="more"></a>

<hr>
<blockquote>
<p><strong>博客更新日志</strong></p>
</blockquote>
<ul>
<li><strong>2020/5/7</strong></li>
</ul>
<ol>
<li>更新文章《《python深度学习》笔记》</li>
</ol>
<p><strong>小结</strong>：今日更新文章<strong>《《python深度学习》笔记》</strong>(2020/5/7 11:14 PV:460 UV:206)</p>
<hr>
<ul>
<li><strong>2020/5/6</strong></li>
</ul>
<ol>
<li>添加文章《《python深度学习》笔记》</li>
</ol>
<p><strong>小结</strong>：今日添加文章<strong>《《python深度学习》笔记》</strong>(2020/5/6 12:08 PV:456 UV:204)</p>
<hr>
<ul>
<li><strong>2020/4/30</strong></li>
</ul>
<ol>
<li>光影画廊模块上线</li>
<li>小幅更新文章《语言之美-古诗丽词》</li>
</ol>
<p><strong>小结</strong>：今日<strong>上线光影画廊模块</strong>,更新<strong>《语言之美-古诗丽词》</strong>(2020/4/30 20:39 PV:436 UV:188)</p>
<hr>
<ul>
<li><strong>2020/4/29</strong></li>
</ul>
<ol>
<li>小幅更新文章《语言之美-古诗丽词》与《语言之美-新句美文》</li>
<li>更改两处滚动标题</li>
</ol>
<p><strong>小结</strong>：今日<strong>更新两篇文章</strong>(2020/4/29 22:34 PV:430 UV:183)</p>
<hr>
<ul>
<li><strong>2020/4/23</strong></li>
</ul>
<ol>
<li>更新文章《利用tf.concat()与np.concatenate来拼接向量》</li>
</ol>
<p><strong>小结</strong>：今日<strong>更新一篇文章</strong>(2020/4/23 10:13 PV:411 UV:165)</p>
<hr>
<ul>
<li><strong>2020/4/22</strong></li>
</ul>
<ol>
<li>添加文章《利用reshape重塑numpy数组》，《利用tf.concat()与np.concatenate来拼接向量》</li>
</ol>
<p><strong>小结</strong>：今日<strong>添加两篇文章</strong>(2020/4/22 10:13 PV:399 UV:158)</p>
<hr>
<ul>
<li><strong>2020/4/20</strong></li>
</ul>
<ol>
<li>更新文章《语言之美-古诗丽词》</li>
</ol>
<p><strong>小结</strong>：今日<strong>大幅更新《语言之美-古诗丽词》并优化文章排版</strong>(2020/4/20 22:05 PV:390 UV:153)</p>
<hr>
<ul>
<li><strong>2020/4/16</strong></li>
</ul>
<ol>
<li>更新文章《《数据结构与算法》笔记(Python语言实现)》(2020/4/16 20:06 PV:385 UV:150)</li>
</ol>
<hr>
<ul>
<li><strong>2020/4/14</strong></li>
</ul>
<ol>
<li>更新文章《Pandas在Python语言下的基础使用》(2020/4/14 22:12 PV:376 UV:145)</li>
</ol>
<hr>
<ul>
<li><strong>2020/4/13</strong></li>
</ul>
<ol>
<li>更新文章《《Python机器学习基础教程》笔记(scikit-learn框架)》</li>
<li>更新文章《python画散点图[plt.scatter()]以及矩阵散点图[pd.scatter_matrix()]详解》（待优化）</li>
<li>暂时搁置文章《Pandas在Python语言下的基础使用》</li>
<li>暂时搁置文章《《数据结构与算法》笔记(Python语言实现)》</li>
</ol>
<p><strong>小结</strong>：今日更新主要<strong>优化文章排版</strong>，<strong>更新两篇文章</strong>(2020/4/13 22:05 PV:374 UV:143)</p>
<hr>
<ul>
<li><strong>2020/4/11</strong></li>
</ul>
<ol>
<li>博客现在已经<strong>能够在文章中插入图片</strong>，但<strong>光影画廊仍然无法在云端显示图片</strong></li>
<li>博客现在已开放<strong>评论留言系统</strong>，并能够<strong>置顶文章</strong></li>
</ol>
<p><strong>小结</strong>：今天<strong>无文章更新</strong>，主要是<strong>完善博客功能</strong>(2020/4/11 22:39 PV:354 UV:138)</p>
]]></content>
  </entry>
  <entry>
    <title>语言之美-古诗丽词</title>
    <url>/2020/04/30/%E8%AF%AD%E8%A8%80%E4%B9%8B%E7%BE%8E-%E5%8F%A4%E8%AF%97%E4%B8%BD%E8%AF%8D/</url>
    <content><![CDATA[<h3 id="《蝶恋花·庭院深深深几许》-宋-欧阳修"><a href="#《蝶恋花·庭院深深深几许》-宋-欧阳修" class="headerlink" title="《蝶恋花·庭院深深深几许》-[宋] 欧阳修"></a>《蝶恋花·庭院深深深几许》-[宋] 欧阳修</h3><blockquote>
<p><strong>庭院深深深几许，杨柳堆烟，帘幕无重数。玉勒雕鞍游冶处，楼高不见章台路。<br>雨横风狂三月暮，门掩黄昏，无计留春住。泪眼问花花不语，乱红飞过秋千去。</strong></p>
</blockquote>
<hr>
<h3 id="《武陵春·风住尘香花已尽》-宋-李清照"><a href="#《武陵春·风住尘香花已尽》-宋-李清照" class="headerlink" title="《武陵春·风住尘香花已尽》-[宋] 李清照"></a>《武陵春·风住尘香花已尽》-[宋] 李清照</h3><blockquote>
<p><strong>风住尘香花已尽，日晚倦梳头。物是人非事事休，欲语泪先流。<br>闻说双溪春尚好，也拟泛轻舟。只恐双溪舴艋舟，载不动许多愁。</strong></p>
</blockquote>
<hr>
<h3 id="《生查子·元夕》-宋-欧阳修"><a href="#《生查子·元夕》-宋-欧阳修" class="headerlink" title="《生查子·元夕》-[宋] 欧阳修"></a>《生查子·元夕》-[宋] 欧阳修</h3><blockquote>
<p><strong>去年元夜时，花市灯如昼。月上柳梢头，人约黄昏后。<br>今年元夜时，月与灯依旧。不见去年人，泪湿春衫袖。</strong></p>
</blockquote>
<hr>
<h3 id="《钗头凤·红酥手》-宋-陆游"><a href="#《钗头凤·红酥手》-宋-陆游" class="headerlink" title="《钗头凤·红酥手》-[宋] 陆游"></a>《钗头凤·红酥手》-[宋] 陆游</h3><blockquote>
<p><strong>红酥手，黄縢酒，满城春色宫墙柳。东风恶，欢情薄。一怀愁绪，几年离索。错、错、错。<br>春如旧，人空瘦，泪痕红浥鲛绡透。桃花落，闲池阁。山盟虽在，锦书难托。莫、莫、莫！</strong></p>
</blockquote>
<a id="more"></a>
<hr>
<h3 id="《陌上花三首》-宋-苏轼"><a href="#《陌上花三首》-宋-苏轼" class="headerlink" title="《陌上花三首》-[宋] 苏轼"></a>《陌上花三首》-[宋] 苏轼</h3><blockquote>
<ul>
<li><strong>陌上开花蝴蝶飞，江山犹是昔人非</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《贺新郎·甚矣吾衰矣》-宋-辛弃疾"><a href="#《贺新郎·甚矣吾衰矣》-宋-辛弃疾" class="headerlink" title="《贺新郎·甚矣吾衰矣》-[宋] 辛弃疾"></a>《贺新郎·甚矣吾衰矣》-[宋] 辛弃疾</h3><blockquote>
<ul>
<li><strong>我见青山多妩媚，料青山见我，应如是。</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《虞美人·雨后同干誉才卿置酒来禽花下作》-宋-叶梦得"><a href="#《虞美人·雨后同干誉才卿置酒来禽花下作》-宋-叶梦得" class="headerlink" title="《虞美人·雨后同干誉才卿置酒来禽花下作》-[宋] 叶梦得"></a>《虞美人·雨后同干誉才卿置酒来禽花下作》-[宋] 叶梦得</h3><blockquote>
<p><strong>落花已作风前舞。又送黄昏雨。晓来庭院半残红。惟有游丝千丈、罥晴空。<br>殷勤花下同携手。更尽杯中酒。美人不用敛蛾眉。我亦多情无奈、酒阑时。</strong></p>
</blockquote>
<hr>
<h3 id="《蝶恋花·春景》-宋-苏轼"><a href="#《蝶恋花·春景》-宋-苏轼" class="headerlink" title="《蝶恋花·春景》-[宋] 苏轼"></a>《蝶恋花·春景》-[宋] 苏轼</h3><blockquote>
<p><strong>花褪残红青杏小。燕子飞时，绿水人家绕。枝上柳绵吹又少。天涯何处无芳草。<br>墙里秋千墙外道。墙外行人，墙里佳人笑。笑渐不闻声渐悄。多情却被无情恼。</strong></p>
</blockquote>
<hr>
<h3 id="《东风第一枝·倾国倾城》-宋-吴文英"><a href="#《东风第一枝·倾国倾城》-宋-吴文英" class="headerlink" title="《东风第一枝·倾国倾城》-[宋] 吴文英"></a>《东风第一枝·倾国倾城》-[宋] 吴文英</h3><blockquote>
<p><strong>倾国倾城，非花非雾，春风十里独步。胜如西子妖绕，更比太真澹泞。铅华不御。漫道有、巫山洛浦。似恁地、标格无双，镇锁画楼深处。<br>曾被风、容易送去。曾被月、等闲留住。似花翻使花羞，似柳任从柳妒。不教歌舞。恐化作、彩云轻举。信下蔡、阳城俱迷，看取宋玉词赋。</strong></p>
</blockquote>
<hr>
<h3 id="《洛神赋》-魏晋-曹植"><a href="#《洛神赋》-魏晋-曹植" class="headerlink" title="《洛神赋》-[魏晋] 曹植"></a>《洛神赋》-[魏晋] 曹植</h3><blockquote>
<ul>
<li><strong>翩若惊鸿，婉若游龙，荣曜秋菊，华茂春松。</strong></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>髣髴兮若轻云之蔽月，飘飖兮若流风之回雪。</strong></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>远而望之，皎若太阳升朝霞；迫而察之，灼若芙蕖出渌波。</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《相见欢》-五代-李煜"><a href="#《相见欢》-五代-李煜" class="headerlink" title="《相见欢》-[五代] 李煜"></a>《相见欢》-[五代] 李煜</h3><blockquote>
<p><strong>林花谢了春红，太匆匆。无奈朝来寒雨晚来风。<br>胭脂泪，相留醉，几时重。自是人生长恨水长东。</strong></p>
</blockquote>
<hr>
<h3 id="《沈园二首》-宋-陆游"><a href="#《沈园二首》-宋-陆游" class="headerlink" title="《沈园二首》-[宋] 陆游"></a>《沈园二首》-[宋] 陆游</h3><blockquote>
<ul>
<li><strong>城上斜阳画角哀，沈园非复旧池台， 伤心桥下春波绿，曾是惊鸿照影来。</strong> </li>
</ul>
</blockquote>
<hr>
<h3 id="《鹊桥仙·纤云弄巧》-宋-秦观"><a href="#《鹊桥仙·纤云弄巧》-宋-秦观" class="headerlink" title="《鹊桥仙·纤云弄巧》-[宋] 秦观"></a>《鹊桥仙·纤云弄巧》-[宋] 秦观</h3><blockquote>
<p><strong>纤云弄巧，飞星传恨，银汉迢迢暗度。 金风玉露一相逢，便胜却、人间无数。<br>柔情似水，佳期如梦，忍顾鹊桥归路。 两情若是久长时，又岂在、朝朝暮暮。</strong></p>
</blockquote>
<hr>
<h3 id="《乞彩笺歌》-唐-韦庄"><a href="#《乞彩笺歌》-唐-韦庄" class="headerlink" title="《乞彩笺歌》-[唐] 韦庄"></a>《乞彩笺歌》-[唐] 韦庄</h3><blockquote>
<ul>
<li><strong>我有歌诗一千首，磨砻山岳罗星斗。开卷长疑雷电惊，挥毫只怕龙蛇走。</strong></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>班班布在时人口，满袖松花都未有。人间无处买烟霞，须知得自神仙手。</strong></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>也知价重连城璧，一纸万金犹不惜。薛涛昨夜梦中来，殷勤劝向君边觅。</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《山居秋暝》-唐-王维"><a href="#《山居秋暝》-唐-王维" class="headerlink" title="《山居秋暝》-[唐] 王维"></a>《山居秋暝》-[唐] 王维</h3><blockquote>
<p><strong>空山新雨后，天气晚来秋。 明月松间照，清泉石上流。<br>竹喧归浣女，莲动下渔舟。 随意春芳歇，王孙自可留。</strong></p>
</blockquote>
<hr>
<h3 id="《芙蓉楼送辛渐》-唐-王昌龄"><a href="#《芙蓉楼送辛渐》-唐-王昌龄" class="headerlink" title="《芙蓉楼送辛渐》-[唐] 王昌龄"></a>《芙蓉楼送辛渐》-[唐] 王昌龄</h3><blockquote>
<p><strong>寒雨连江夜入吴，平明送客楚山孤。 洛阳亲友如相问，一片冰心在玉壶。</strong></p>
</blockquote>
<hr>
<h3 id="《无题》-唐-李商隐"><a href="#《无题》-唐-李商隐" class="headerlink" title="《无题》-[唐] 李商隐"></a>《无题》-[唐] 李商隐</h3><blockquote>
<p><strong>照梁初有情，出水旧知名。裙衩芙蓉小，钗茸翡翠轻。<br>锦长书郑重，眉细恨分明。莫近弹棋局，中心最不平。</strong></p>
</blockquote>
<hr>
<h3 id="《乐府-古相思曲》-两汉-佚名"><a href="#《乐府-古相思曲》-两汉-佚名" class="headerlink" title="《乐府.古相思曲》-[两汉] 佚名"></a>《乐府.古相思曲》-[两汉] 佚名</h3><p>　</p>
<blockquote>
<ul>
<li><strong>君似明月我似雾，雾随月隐空留露。<br>君善抚琴我善舞，曲终人离心若堵。<br>只缘感君一回顾，使我思君朝与暮。<br>魂随君去终不悔, 绵绵相思为君苦。<br>相思苦，凭谁诉？遥遥不知君何处。<br>扶门切思君之嘱，登高望断天涯路。</strong></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li><strong>十三与君初相识，王侯宅里弄丝竹。<br>只缘感君一回顾，使我思君朝与暮。<br>再见君时妾十五，且为君作霓裳舞。<br>可叹年华如朝露，何时衔泥巢君屋？</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《长命女·春日宴》-五代-冯延巳"><a href="#《长命女·春日宴》-五代-冯延巳" class="headerlink" title="《长命女·春日宴》-[五代] 冯延巳"></a>《长命女·春日宴》-[五代] 冯延巳</h3><blockquote>
<p><strong>春日宴，绿酒一杯歌一遍。再拜陈三愿：一愿郎君千岁，二愿妾身常健，三愿如同梁上燕，岁岁长相见。</strong></p>
</blockquote>
<hr>
<h3 id="《听筝》-唐-李端"><a href="#《听筝》-唐-李端" class="headerlink" title="《听筝》-[唐] 李端"></a>《听筝》-[唐] 李端</h3><blockquote>
<p><strong>鸣筝金粟柱，素手玉房前。欲得周郎顾，时时误拂弦。</strong></p>
</blockquote>
<hr>
<h3 id="《陌上花开，可缓缓归矣》-五代-吴越王"><a href="#《陌上花开，可缓缓归矣》-五代-吴越王" class="headerlink" title="《陌上花开，可缓缓归矣》-[五代] 吴越王"></a>《陌上花开，可缓缓归矣》-[五代] 吴越王</h3><blockquote>
<p><strong>陌上花开，可缓缓归矣</strong></p>
</blockquote>
<hr>
<h3 id="《赠去婢》-唐-崔郊"><a href="#《赠去婢》-唐-崔郊" class="headerlink" title="《赠去婢》-[唐] 崔郊"></a>《赠去婢》-[唐] 崔郊</h3><blockquote>
<p><strong>公子王孙逐后尘，绿珠垂泪滴罗巾。侯门一入深如海，从此萧郎是路人。</strong></p>
</blockquote>
<hr>
<h3 id="《丑奴儿·书博山道中壁》-宋-辛弃疾"><a href="#《丑奴儿·书博山道中壁》-宋-辛弃疾" class="headerlink" title="《丑奴儿·书博山道中壁》-[宋] 辛弃疾"></a>《丑奴儿·书博山道中壁》-[宋] 辛弃疾</h3><blockquote>
<p><strong>少年不识愁滋味，爱上层楼。爱上层楼，为赋新词强说愁。<br>而今识尽愁滋味，欲说还休。欲说还休，却道天凉好个秋。</strong></p>
</blockquote>
<hr>
<h3 id="《题都城南庄》-唐-崔护"><a href="#《题都城南庄》-唐-崔护" class="headerlink" title="《题都城南庄》-[唐] 崔护"></a>《题都城南庄》-[唐] 崔护</h3><blockquote>
<p><strong>去年今日此门中，人面桃花相映红。 人面不知何处去，桃花依旧笑春风。</strong></p>
</blockquote>
<hr>
<h3 id="《闺怨》-唐-王昌龄"><a href="#《闺怨》-唐-王昌龄" class="headerlink" title="《闺怨》-[唐] 王昌龄"></a>《闺怨》-[唐] 王昌龄</h3><blockquote>
<p><strong>闺中少妇不知愁，春日凝妆上翠楼。 忽见陌头杨柳色，悔教夫婿觅封侯。</strong></p>
</blockquote>
<hr>
<h3 id="《采薇》-先秦-佚名"><a href="#《采薇》-先秦-佚名" class="headerlink" title="《采薇》-[先秦] 佚名"></a>《采薇》-[先秦] 佚名</h3><blockquote>
<ul>
<li><strong>昔我往矣，杨柳依依。今我来思，雨雪霏霏。</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《乌衣巷》-唐-刘禹锡"><a href="#《乌衣巷》-唐-刘禹锡" class="headerlink" title="《乌衣巷》-[唐] 刘禹锡"></a>《乌衣巷》-[唐] 刘禹锡</h3><blockquote>
<p><strong>朱雀桥边野草花，乌衣巷口夕阳斜。 旧时王谢堂前燕，飞入寻常百姓家。</strong></p>
</blockquote>
<hr>
<h3 id="《木兰词·拟古决绝词柬友》-清-纳兰性德"><a href="#《木兰词·拟古决绝词柬友》-清-纳兰性德" class="headerlink" title="《木兰词·拟古决绝词柬友》-[清] 纳兰性德"></a>《木兰词·拟古决绝词柬友》-[清] 纳兰性德</h3><blockquote>
<ul>
<li><strong>人生若只如初见，何事秋风悲画扇。</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《青玉案·凌波不过横塘路》-宋-贺铸"><a href="#《青玉案·凌波不过横塘路》-宋-贺铸" class="headerlink" title="《青玉案·凌波不过横塘路》-[宋] 贺铸"></a>《青玉案·凌波不过横塘路》-[宋] 贺铸</h3><blockquote>
<p><strong>凌波不过横塘路。但目送、芳尘去。锦瑟华年谁与度。月桥花院，琐窗朱户。只有春知处。<br>飞云冉冉蘅皋暮。彩笔新题断肠句。若问闲情都几许。一川烟草，满城风絮。梅子黄时雨。</strong></p>
</blockquote>
<hr>
<h3 id="《采桑子·时光只解催人老》-宋-晏殊"><a href="#《采桑子·时光只解催人老》-宋-晏殊" class="headerlink" title="《采桑子·时光只解催人老》-[宋] 晏殊"></a>《采桑子·时光只解催人老》-[宋] 晏殊</h3><blockquote>
<ul>
<li><strong>时光只解催人老，不信多情，长恨离亭，泪滴春衫酒易醒。</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《越人歌》-春秋-刘向"><a href="#《越人歌》-春秋-刘向" class="headerlink" title="《越人歌》-[春秋] 刘向"></a>《越人歌》-[春秋] 刘向</h3><blockquote>
<ul>
<li><strong>山有木兮木有枝，心悦君兮君不知。</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《白头吟》-汉-卓文君"><a href="#《白头吟》-汉-卓文君" class="headerlink" title="《白头吟》-[汉] 卓文君"></a>《白头吟》-[汉] 卓文君</h3><blockquote>
<ul>
<li><strong>愿得一心人，白头不相离。</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《迢迢牵牛星》-汉-佚名"><a href="#《迢迢牵牛星》-汉-佚名" class="headerlink" title="《迢迢牵牛星》-[汉] 佚名"></a>《迢迢牵牛星》-[汉] 佚名</h3><blockquote>
<p><strong>迢迢牵牛星，皎皎河汉女。<br>纤纤擢素手，札札弄机杼。<br>终日不成章，泣涕零如雨；<br>河汉清且浅，相去复几许！<br>盈盈一水间，脉脉不得语。</strong></p>
</blockquote>
<hr>
<h3 id="《蝶恋花·阅尽天涯离别苦》-清-王国维"><a href="#《蝶恋花·阅尽天涯离别苦》-清-王国维" class="headerlink" title="《蝶恋花·阅尽天涯离别苦》-[清] 王国维"></a>《蝶恋花·阅尽天涯离别苦》-[清] 王国维</h3><blockquote>
<ul>
<li><strong>待把相思灯下诉，一缕新欢，旧恨千千缕。最是人间留不住，朱颜辞镜花辞树。</strong></li>
</ul>
</blockquote>
<hr>
<h3 id="《长相思·一重山》-五代-李煜"><a href="#《长相思·一重山》-五代-李煜" class="headerlink" title="《长相思·一重山》-[五代] 李煜"></a>《长相思·一重山》-[五代] 李煜</h3><blockquote>
<p><strong>一重山，两重山。山远天高烟水寒，相思枫叶丹。<br>菊花开，菊花残。塞雁高飞人未还，一帘风月闲。</strong></p>
</blockquote>
<hr>
<h3 id="《青玉案·元夕》-宋-辛弃疾"><a href="#《青玉案·元夕》-宋-辛弃疾" class="headerlink" title="《青玉案·元夕》-[宋] 辛弃疾"></a>《青玉案·元夕》-[宋] 辛弃疾</h3><blockquote>
<p><strong>东风夜放花千树。更吹落、星如雨。宝马雕车香满路。凤箫声动，玉壶光转，一夜鱼龙舞。<br>蛾儿雪柳黄金缕。笑语盈盈暗香去。众里寻他千百度。蓦然回首，那人却在，灯火阑珊处。</strong></p>
</blockquote>
<hr>
<h3 id="《醉花阴·薄雾浓云愁永昼》-宋-李清照"><a href="#《醉花阴·薄雾浓云愁永昼》-宋-李清照" class="headerlink" title="《醉花阴·薄雾浓云愁永昼》-[宋] 李清照"></a>《醉花阴·薄雾浓云愁永昼》-[宋] 李清照</h3><blockquote>
<p><strong>薄雾浓云愁永昼，瑞脑消金兽。佳节又重阳，玉枕纱厨，半夜凉初透。<br>东篱把酒黄昏后，有暗香盈袖。莫道不销魂，帘卷西风，人比黄花瘦。</strong></p>
</blockquote>
<hr>
<h3 id="《山亭夏日》-唐-高骈"><a href="#《山亭夏日》-唐-高骈" class="headerlink" title="《山亭夏日》-[唐] 高骈"></a>《山亭夏日》-[唐] 高骈</h3><blockquote>
<p><strong>绿树阴浓夏日长，楼台倒影入池塘。<br>水晶帘动微风起，满架蔷薇一院香。</strong></p>
</blockquote>
<hr>
<h3 id="《书湖阴先生壁》-宋-王安石"><a href="#《书湖阴先生壁》-宋-王安石" class="headerlink" title="《书湖阴先生壁》-[宋] 王安石"></a>《书湖阴先生壁》-[宋] 王安石</h3><blockquote>
<p><strong>茅檐长扫净无苔，花木成畦手自栽。<br>一水护田将绿绕，两山排闼送青来。</strong></p>
</blockquote>
<hr>
<h3 id="《鹧鸪天·彩袖殷勤捧玉钟》-宋-晏几道"><a href="#《鹧鸪天·彩袖殷勤捧玉钟》-宋-晏几道" class="headerlink" title="《鹧鸪天·彩袖殷勤捧玉钟》-[宋] 晏几道"></a>《鹧鸪天·彩袖殷勤捧玉钟》-[宋] 晏几道</h3><blockquote>
<p><strong>彩袖殷勤捧玉钟。当年拚却醉颜红。舞低杨柳楼心月，歌尽桃花扇影风。<br>从别后，忆相逢。几回魂梦与君同。今宵剩把银釭照，犹恐相逢是梦中。</strong></p>
</blockquote>
<hr>
<h3 id="《上邪》-汉-佚名"><a href="#《上邪》-汉-佚名" class="headerlink" title="《上邪》-[汉] 佚名"></a>《上邪》-[汉] 佚名</h3><blockquote>
<p><strong>上邪，<br>我欲与君相知，<br>长命无绝衰。<br>山无陵，<br>江水为竭。<br>冬雷震震，<br>夏雨雪。<br>天地合，<br>乃敢与君绝。</strong></p>
</blockquote>
<hr>
<h3 id="《晓出净慈寺送林子方》-宋-杨万里"><a href="#《晓出净慈寺送林子方》-宋-杨万里" class="headerlink" title="《晓出净慈寺送林子方》-[宋] 杨万里"></a>《晓出净慈寺送林子方》-[宋] 杨万里</h3><blockquote>
<p><strong>毕竟西湖六月中，风光不与四时同。<br>接天莲叶无穷碧，映日荷花别样红。</strong></p>
</blockquote>
<hr>
<h3 id="《一剪梅》-明-唐寅"><a href="#《一剪梅》-明-唐寅" class="headerlink" title="《一剪梅》-[明] 唐寅"></a>《一剪梅》-[明] 唐寅</h3><blockquote>
<p><strong>雨打梨花深闭门，忘了青春，误了青春。赏心乐事共谁论？花下销魂，月下销魂。<br>愁聚眉峰尽日颦，千点啼痕，万点啼痕。晓看天色暮看云，行也思君，坐也思君。</strong></p>
</blockquote>
<hr>
<h3 id="《清平调·其一》-唐-李白"><a href="#《清平调·其一》-唐-李白" class="headerlink" title="《清平调·其一》-[唐] 李白"></a>《清平调·其一》-[唐] 李白</h3><blockquote>
<p><strong>云想衣裳花想容，春风拂槛露华浓。<br>若非群玉山头见，会向瑶台月下逢。</strong></p>
</blockquote>
<hr>
<h3 id="《江城子·乙卯正月二十日夜记梦》-宋-苏轼"><a href="#《江城子·乙卯正月二十日夜记梦》-宋-苏轼" class="headerlink" title="《江城子·乙卯正月二十日夜记梦》-[宋] 苏轼"></a>《江城子·乙卯正月二十日夜记梦》-[宋] 苏轼</h3><blockquote>
<p><strong>十年生死两茫茫，不思量，自难忘。千里孤坟，无处话凄凉。纵使相逢应不识，尘满面，鬓如霜。<br>夜来幽梦忽还乡，小轩窗，正梳妆。相顾无言，惟有泪千行。料得年年肠断处，明月夜，短松冈。</strong></p>
</blockquote>
]]></content>
      <categories>
        <category>佳句收录</category>
        <category>古诗丽词</category>
      </categories>
      <tags>
        <tag>语言之美</tag>
      </tags>
  </entry>
  <entry>
    <title>语言之美-新句美文</title>
    <url>/2020/04/29/%E8%AF%AD%E8%A8%80%E4%B9%8B%E7%BE%8E-%E6%96%B0%E5%8F%A5%E7%BE%8E%E6%96%87/</url>
    <content><![CDATA[<blockquote>
<p>《波兰来客》 -北岛</p>
</blockquote>
<ul>
<li><strong>年轻时我们都有梦想，关于文字，关于爱情，关于穿越世界的旅行。现在我们夜深饮酒杯子撞在一起，听到的都是梦破碎的声音。</strong></li>
</ul>
<hr>
<blockquote>
<p>《红玫瑰与白玫瑰》-张爱玲 </p>
</blockquote>
<ul>
<li><strong>也许每一个男子全都有过这样的两个女人，至少两个。娶了红玫瑰，久而久之，红的变了墙上的一抹蚊子血，白的还是“床前明月光”；娶了白玫瑰，白的便是衣服上的一粒饭粘子，红的却是心口上的一颗朱砂痣。</strong></li>
</ul>
<hr>
<blockquote>
<p>《在细雨中呼喊》-余华 </p>
</blockquote>
<ul>
<li><strong>死亡不是失去生命，而是走出了时间。</strong></li>
</ul>
<hr>
<blockquote>
<p>《生命最后的读书会》-[美] 威尔·施瓦尔贝 </p>
</blockquote>
<ul>
<li><strong>假如你不愿祝福他的王国，那么不要为之祈祷。假如你愿意，不能只靠祈祷，还必须为之努力。-《天国降临》</strong></li>
</ul>
<a id="more"></a>
<hr>
<blockquote>
<p>《江海共余生》-春和</p>
</blockquote>
<ul>
<li><strong>山河远阔，人间星河，无一是你，无一不是你。</strong></li>
</ul>
<hr>
<blockquote>
<p>《十里红妆女儿梦》-何晓道</p>
</blockquote>
<ul>
<li><strong>待我长发及腰，少年娶我可好？待你青丝绾正，铺十里红妆可愿？ 却怕长发及腰，少年倾心他人。待你青丝绾正，笑看君怀她笑颜。时待我发齐腰长，愿与梦郎诉衷肠。半生缠绵报君享，此情绵绵意长长。时待我发齐腰长，轻舞霓裳意飞扬。襄王神女应无恙，巫山云雨梦得度偿。时待我发齐腰长，红颜老去珠也黄。</strong></li>
</ul>
<hr>
<blockquote>
<p>《思念往昔》-张小娴</p>
</blockquote>
<ul>
<li><strong>我没有很刻意地去想念你，因为我知道遇到了就应该感恩，路过了就应该释怀。我只是在很多个小瞬间想起你。比如，一部电影，一首歌，一句歌词，一条马路和无数个闭上眼的瞬间。</strong></li>
</ul>
<hr>
<blockquote>
<p>《后来》-2017年刘若英演唱会后，出自网络</p>
</blockquote>
<p><strong>初闻不知曲中意，再闻已是曲中人。<br>既然已是曲中人，何必再听曲中曲。<br>曲中轻忆梦中人，梦醒时分叹红尘。<br>曲终人散梦已醒，何处再寻梦中人。<br>梦中合唱凤求凰，梦醒独奏离别赋。<br>即知曲人存于梦，何故执于曲外人。<br>多少痴梦多少等，难诉痴情曲中人。<br>一萧一页红尘事，一弦一曲了人生。<br>既然已是曲中人，何必再悟曲中意。<br>不愿再做曲中人，奈何越听越沉沦。<br>曲中曲，人中人，曲散人终离，曲终人散早成空。<br>一曲肝肠断，天涯何处觅知音。</strong></p>
<hr>
<blockquote>
<p>《当幸福来敲门》-电影</p>
</blockquote>
<ul>
<li><strong>当人们做不到一些事情的时候，他们就会对你说你也同样不可能。如果你有梦想，就去捍卫它。</strong></li>
</ul>
<hr>
<blockquote>
<p>《寄生虫》影评-Hong-King改编自网络</p>
</blockquote>
<ul>
<li><strong>有人说电影《寄生虫》太过灰暗，描述了穷富之间难以跨越的鸿沟，书写了生而为人难以逃脱的宿命。但这是阶级的悲剧吗？我更倾向于这是选择的悲剧，亦是悲剧的选择。他们本可以选择上进、勤恳、沟通，却沉沦于寄生和懒惰，暴力和杀戮。生活不是永恒的暴雨倾盆，总有阳光灿烂的时候，但这时候，就要看你如何选择。是躲在屋里仇视外面的阳光，还是冲到阳光下，努力地活一把。</strong></li>
</ul>
<hr>
<blockquote>
<p>《Like That》-网易云评论</p>
</blockquote>
<ul>
<li><strong>我会变得更好，因为你，但不是为了你。</strong></li>
</ul>
<hr>
<blockquote>
<p>《记得》-网易云评论</p>
</blockquote>
<ul>
<li><strong>无论我们以后生疏成什么样子，请记得曾经我对你的好是真的。剩下的路就不陪你走了，要照顾好自己，不是每个人都是我，三生有幸，遇见你纵使悲凉也是情。</strong></li>
</ul>
<hr>
<blockquote>
<p>《被讨厌的勇气》-[日] 岸见一郎/古贺史健  </p>
</blockquote>
<ul>
<li><strong>在阿德勒眼中，理想的人际关系大概是“我爱你，但与你无关”。他认为每个人的课题都是分离又独特的。我怎么爱你，这是我的课题，而你要不要接受我的爱，这是你的课题。</strong></li>
</ul>
<hr>
<blockquote>
<p>摘自网络</p>
</blockquote>
<ul>
<li><p><strong>有人说，林深时见鹿，海蓝时见鲸，梦醒时见你。可实际，林深时起雾，海蓝时浪涌，梦醒时夜续。但终究，鹿踏雾而来，鲸随浪而起。你没回头又怎知我不在？</strong></p>
</li>
<li><p><strong>你认为的完美爱情是从一而终，而现实中的完美爱情，更像是和生活的握手言和。永远不要说永远。</strong></p>
</li>
<li><p><strong>我永远喜欢你，不是说我会十年二十年一辈子都喜欢你，而是指，我这一刻喜欢你的程度，让我有勇气说出来我永远喜欢你。</strong></p>
</li>
<li><p><strong>过程才是生命，两端都是死亡。</strong></p>
</li>
<li><p><strong>每当有人问起，为什么我不恋爱的时候，我都以麻烦为由搪塞过去。又有人开始问我到底喜欢过谁没有，我也轻描淡写地表示否定。无数的朋友告诉我，或许是你还没碰到过真正喜欢的人吧，我却没法开口告诉他们，其实我曾经碰到过，碰得太早，以至于我没来得及分清，也没来得及弄明白。</strong></p>
</li>
<li><p><strong>遗憾吗？那么喜欢连张合影都没有</strong></p>
</li>
<li><p><strong>没人嘲笑你的梦想，他们只是嘲笑你的实力</strong></p>
</li>
<li><p><strong>其实我也是很羡慕别的小女生收到花，收到唇膏，收到各种各样的惊喜，我嘴上说，反正我都买得起，但在心里还是偷偷羡慕过的，所以希望我的恋人，拜托拜托，送花给我，偷偷准备热门色号的唇膏给我，摸摸我的头，天冷的时候把我的手放在你的口袋里，俗气而又热烈的喜欢我。</strong></p>
</li>
<li><p><strong>和你一起环游世界拍照，就是一口气做了三件最爱的事情。</strong> —#孔维与诗苑#</p>
</li>
<li><p><strong>看你周围，你未来另一半此时正在某个地方，可能坐计程车、看小说、做数学题，收到情书、烹饪、身处旅途、阴天躲在被子里哭、学习怎么打扮、喂猫、给大狗洗澡。就在现在，就在此时此刻，未来注定要和你在一起的那个人，正在努力制造着你们一起躺在床上的那无数个夜晚里准备讲给你的回忆和故事。</strong>—博主:#小羊爱吃酱肘子#</p>
</li>
<li><p><strong>温柔仅供参考，一切请以生气时间为准</strong></p>
</li>
<li><p><strong>我是檐上三寸雪，你是人间惊鸿客</strong></p>
</li>
<li><p><strong>去做你害怕的事，最后你会发现：其实不过如此。</strong></p>
</li>
<li><p><strong>把欺负你的人打疼，一次就够了。</strong></p>
</li>
<li><p><strong>苦难就是苦难，是我们自己足够坚强挺过了苦难，是我们自己从苦难中不断成长。</strong></p>
</li>
<li><p><strong>虽然也会有数不尽的悲伤，但我终将与你相遇</strong></p>
</li>
</ul>
<hr>
<blockquote>
<p>Hong-King</p>
</blockquote>
<ul>
<li><strong>我曾经害怕死亡，有太多人类的奇迹是我看不到的，但我没发现同时我也是幸运的，这个时代本身就有很多奇迹等着我们去创造。</strong></li>
</ul>
]]></content>
      <categories>
        <category>佳句收录</category>
        <category>新句美文</category>
      </categories>
      <tags>
        <tag>语言之美</tag>
      </tags>
  </entry>
  <entry>
    <title>《python深度学习》笔记</title>
    <url>/2020/05/07/%E3%80%8Apython%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h1 id="第一章-什么是深度学习"><a href="#第一章-什么是深度学习" class="headerlink" title="第一章 什么是深度学习"></a>第一章 什么是深度学习</h1><h2 id="1-1-人工智能、机器学习与深度学习"><a href="#1-1-人工智能、机器学习与深度学习" class="headerlink" title="1.1　人工智能、机器学习与深度学习"></a><strong>1.1　人工智能、机器学习与深度学习</strong></h2><blockquote>
<p>人工智能、机器学习与深度学习这三者之间的关系：{深度学习}&lt;{机器学习}&lt;{人工智能}</p>
</blockquote>
<h3 id="1-1-1-人工智能"><a href="#1-1-1-人工智能" class="headerlink" title="1.1.1　人工智能"></a>1.1.1　人工智能</h3><ul>
<li>人工智能的简洁定义如下：<strong>努力将通常由人类完成的智力任务自动化。</strong>因此，<strong>人工智能是一个综合性的领域，不仅包括机器学习与深度学习，还包括更多不涉及学习的方法</strong>。</li>
</ul>
<h3 id="1-1-2-机器学习"><a href="#1-1-2-机器学习" class="headerlink" title="1.1.2　机器学习"></a>1.1.2　机器学习</h3><ul>
<li><p>在经典的程序设计（即符号主义人工智能的范式）中，人们<strong>输入的是规则（即程序）</strong>和需要根据这些规则<strong>进行处理的数据</strong>，系统<strong>输出的是答案</strong>。</p>
</li>
<li><p>在机器学习中，人们<strong>输入的是数据</strong>和从这些数据中<strong>预期得到的答案</strong>，系统<strong>输出的是规则</strong>。这些规则随后可应用于新的数据，并使计算机自主生成答案。</p>
</li>
<li><p>机器学习系统是<strong>训练出来的</strong>，而不是明确地用程序编写出来的。</p>
</li>
<li><p>机器学习（尤其是深度学习）呈现出相对较少的数学理论（可能太少了），并且是以工程为导向的。这是一门<strong>需要上手实践的学科</strong>，想法<strong>更多地是靠实践来证明</strong>，而不是靠理论推导。</p>
</li>
</ul>
<a id="more"></a>
<h3 id="1-1-3-从数据中学习表示"><a href="#1-1-3-从数据中学习表示" class="headerlink" title="1.1.3　从数据中学习表示"></a>1.1.3　从数据中学习表示</h3><ul>
<li><p>机器学习和深度学习的核心问题在于<strong>有意义地变换数据</strong>，换句话说，在于学习输入数据的<strong>有用表示（representation）</strong>——这种表示可以让数据更接近预期输出。</p>
</li>
<li><p>什么是<strong>表示</strong>：这一概念的核心在于<strong>以一种不同的方式来查看数据（即表征数据或将数据编码）</strong>。例如，彩色图像可以编码为RGB（红-绿-蓝）格式或HSV（色相-饱和度-明度）格式，这是对相同数据的两种不同表示。在处理某些任务时，使用某种表示可能会很困难，但换用另一种表示就会变得很简单。</p>
</li>
<li><p>所有机器学习算法都包括<strong>自动寻找这样一种变换</strong>：这种变换可以根据任务将数据转化为更加有用的表示。机器学习算法在寻找这些变换时通常没有什么创造性，而仅仅是遍历一组预先定义好的操作，这组操作叫作<strong>假设空间（hypothesis space）</strong>。</p>
</li>
<li><p>这就是机器学习的技术定义：<strong>在预先定义好的可能性空间中，利用反馈信号的指引来寻找输入数据的有用表示</strong>。</p>
</li>
</ul>
<h3 id="1-1-4-深度学习之“深度”"><a href="#1-1-4-深度学习之“深度”" class="headerlink" title="1.1.4　深度学习之“深度”"></a>1.1.4　深度学习之“深度”</h3><ul>
<li><p>深度学习是机器学习的一个分支领域：它是从数据中学习表示的一种新方法，强调从连续的<strong>层（layer）</strong>中进行学习，这些层对应于<strong>越来越有意义的表示</strong>。</p>
</li>
<li><p>“深度学习”中的“深度”指的并不是利用这种方法所获取的更深层次的理解，而是指<strong>一系列连续的表示层</strong>。数据模型中包含多少层，这被称为模型的<strong>深度（depth）</strong>。这一领域的其他名称包括分层表示学习（layered representations learning）和层级表示学习（hierarchical representations learning）。</p>
</li>
<li><p>现代深度学习通常包含<strong>数十个甚至上百个连续的表示层</strong>，这些表示层全都是从训练数据中自动学习的。与此相反，其他机器学习方法的重点往往是仅仅学习一两层的数据表示，因此有时也被称为<strong>浅层学习（shallow learning）</strong>。</p>
</li>
<li><p>在深度学习中，这些分层表示几乎总是通过叫作<strong>神经网络（neural network）</strong>的模型来学习得到的。</p>
</li>
</ul>
<h3 id="1-1-5-理解深度学习的工作原理"><a href="#1-1-5-理解深度学习的工作原理" class="headerlink" title="1.1.5　理解深度学习的工作原理"></a>1.1.5　理解深度学习的工作原理</h3><ul>
<li><p>神经网络中每层对输入数据所做的具体操作保存在该层的<strong>权重（weight）</strong>中，其本质是一串数字。用术语来说，每层实现的变换由其权重来<strong>参数化（parameterize，见图 1-7）</strong>。权重有时<br>也被称为该层的<strong>参数（parameter）</strong>。在这种语境下，学习的意思是<strong>为神经网络的所有层找到一组权重值，使得该网络能够将每个示例输入与其目标正确地一一对应</strong>。</p>
</li>
<li><p>想要控制神经网络的输出，就需要能够衡量该输出与预期值之间的距离。这是神经网络<strong>损失函数（loss function）</strong>的任务，该函数也叫<strong>目标函数（objective function）</strong>。损失函数的输入是网络预测值与真实目标值（即你希望网络输出的结果），然后计算一个距离值，衡量该网络在这个示例上的效果好坏。</p>
</li>
<li><p>深度学习的基本技巧是利用这个距离值作为反馈信号来对权重值进行微调，以降低当前示例对应的损失值。这种调节由<strong>优化器（optimizer）</strong>来完成，它实现了所谓的<strong>反向传播（backpropagation）算法</strong>，这是深度学习的<strong>核心算法</strong>。</p>
</li>
</ul>
<h3 id="1-1-8-人工智能的未来"><a href="#1-1-8-人工智能的未来" class="headerlink" title="1.1.8　人工智能的未来"></a>1.1.8　人工智能的未来</h3><ul>
<li><strong>不要相信短期的炒作，但一定要相信长期的愿景。人工智能可能需要一段时间才能充分发挥其潜力。这一潜力的范围大到难以想象，但人工智能终将到来，它将以一种奇妙的方式改变我们的世界。</strong></li>
</ul>
<h2 id="1-2-深度学习之前：机器学习简史"><a href="#1-2-深度学习之前：机器学习简史" class="headerlink" title="1.2　深度学习之前：机器学习简史"></a><strong>1.2　深度学习之前：机器学习简史</strong></h2><blockquote>
<p>深度学习已经得到了人工智能历史上前所未有的公众关注度和产业投资，但这并不是机器学习的第一次成功。可以这样说，当前工业界所使用的绝大部分机器学习算法都不是深度学习算法。深度学习不一定总是解决问题的正确工具：有时没有足够的数据，深度学习不适用；有时用其他算法可以更好地解决问题。如果你第一次接触的机器学习就是深度学习，那你可能会发现手中握着一把深度学习“锤子”，而所有机器学习问题看起来都像是“钉子”。为了避免陷入这个误区，唯一的方法就是熟悉其他机器学习方法并在适当的时候进行实践。</p>
</blockquote>
<h3 id="1-2-1-概率建模"><a href="#1-2-1-概率建模" class="headerlink" title="1.2.1　概率建模"></a>1.2.1　概率建模</h3><ul>
<li><p><strong>概率建模（probabilistic modeling）</strong>是统计学原理在数据分析中的应用。它是最早的机器学习形式之一，至今仍在广泛使用。</p>
</li>
<li><p>其中最有名的算法之一就是<strong>朴素贝叶斯算法</strong>:它假设输入数据的特征都是独立的。这是一个很强的假设，或者说“朴素的”假设，其名称正来源于此。</p>
</li>
<li><p>另一个密切相关的<strong>分类算法</strong>模型是 <strong>logistic 回归（logistic regression，简称 logreg）</strong>，它有时被认为是现代机器学习的“hello world”。面对一个数据集，数据科学家<strong>通常会首先尝试使用这个算法</strong>，以便初步熟悉手头的分类任务。</p>
</li>
</ul>
<h3 id="1-2-2-早期神经网络"><a href="#1-2-2-早期神经网络" class="headerlink" title="1.2.2　早期神经网络"></a>1.2.2　早期神经网络</h3><ul>
<li>反向传播算法——一种利用梯度下降优化来训练一系列参数化运算链的方法（笔记后面将给出这些概念的具体定义）</li>
</ul>
<h3 id="1-2-3-核方法"><a href="#1-2-3-核方法" class="headerlink" title="1.2.3　核方法"></a>1.2.3　核方法</h3><ul>
<li><p>核方法是一组分类算法，其中最有名的就是<strong>支持向量机（SVM，support vector machine）</strong>。</p>
</li>
<li><p>SVM 的目标是通过在属于两个不同类别的两组数据点之间找到良好<strong>决策边界（decisionboundary）</strong>来解决分类问题。</p>
</li>
<li><p>SVM 通过两步来寻找决策边界:</p>
</li>
</ul>
<ol>
<li>将数据映射到一个新的高维表示，这时决策边界可以用一个超平面来表示（如果数据是二维的，那么超平面就是一条直线）。</li>
<li>尽量让超平面与每个类别最近的数据点之间的<strong>距离最大化</strong>，从而计算出良好决策边界（分割超平面），这一步叫作<strong>间隔最大化（maximizing the margin）</strong>。</li>
</ol>
<ul>
<li><p>将数据映射到高维表示从而使分类问题简化，这一技巧可能听起来很不错，但在实践中通常是难以计算的。这时就需要用到<strong>核技巧（kernel trick，核方法正是因这一核心思想而得名）</strong>。其基本思想是：要想在新的表示空间中找到良好的决策超平面，你不需要在新空间中直接计算点的坐标，只需要在新空间中计算点对之间的距离，而利用<strong>核函数（kernel function）</strong>可以高效地完成这种计算。核函数是一个在计算上能够实现的操作，将原始空间中的任意两点映射为这两点在目标表示空间中的距离，完全避免了对新表示进行直接计算。核函数通常是人为选择的，而不是从数据中学到的。对于 SVM 来说，只有分割超平面是通过学习得到的。</p>
</li>
<li><p>SVM 很难扩展到大型数据集，并且在图像分类等感知问题上的效果也不好。SVM是一种比较浅层的方法，因此要想将其应用于感知问题，首先需要手动提取出有用的表示（这叫作<strong>特征工程</strong>），这一步骤很难，而且不稳定。</p>
</li>
</ul>
<h3 id="1-2-4-决策树、随机森林与梯度提升机"><a href="#1-2-4-决策树、随机森林与梯度提升机" class="headerlink" title="1.2.4　决策树、随机森林与梯度提升机"></a>1.2.4　决策树、随机森林与梯度提升机</h3><ul>
<li><strong>梯度提升方法</strong>可能是目前处理<strong>非感知数据</strong>最好的算法之一（如果非要加个“之一”的话）。</li>
</ul>
<h3 id="1-2-7-机器学习现状"><a href="#1-2-7-机器学习现状" class="headerlink" title="1.2.7　机器学习现状"></a>1.2.7　机器学习现状</h3><ul>
<li>梯度提升机用于<strong>处理结构化数据的问题</strong>，而深度学习则用于<strong>图像分类等感知问题</strong>。使用前一种方法的人几乎都使用优秀的<strong>XGBoost库</strong>，它同时支持数据科学最流行的两种语言：Python 和 R。使用深度学习的 Kaggle 参赛者则大多使用 <strong>Keras 库</strong>，因为它易于使用，非常灵活，并且支持Python。</li>
</ul>
<h2 id="1-3-为什么是深度学习，为什么是现在"><a href="#1-3-为什么是深度学习，为什么是现在" class="headerlink" title="1.3　为什么是深度学习，为什么是现在"></a><strong>1.3　为什么是深度学习，为什么是现在</strong></h2><blockquote>
<p>由于这一领域是靠实验结果而不是理论指导的，所以只有当合适的数据和硬件可用于尝试新想法时（或者将旧想法的规模扩大，事实往往也是如此），才可能出现算法上的改进。机器学习不是数学或物理学，靠一支笔和一张纸就能实现重大进展。它是一门工程科学。在 20 世纪 90 年代和 21 世纪前十年，真正的瓶颈在于数据和硬件。但在这段时间内发生了下面这些事情：互联网高速发展，并且针对游戏市场的需求开发出了高性能图形芯片。</p>
</blockquote>
<hr>
<h1 id="第二章-神经网络的数学基础"><a href="#第二章-神经网络的数学基础" class="headerlink" title="第二章 神经网络的数学基础"></a>第二章 神经网络的数学基础</h1>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>《python深度学习》</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>深度学习</tag>
      </tags>
  </entry>
  <entry>
    <title>《数学建模方法与应用》笔记</title>
    <url>/2020/05/04/%E3%80%8A%E6%95%B0%E5%AD%A6%E5%BB%BA%E6%A8%A1%E6%96%B9%E6%B3%95%E4%B8%8E%E5%BA%94%E7%94%A8%E3%80%8B%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h2 id="图与网络模型及方法"><a href="#图与网络模型及方法" class="headerlink" title="图与网络模型及方法"></a><strong>图与网络模型及方法</strong></h2><hr>
<h3 id="1-概论"><a href="#1-概论" class="headerlink" title="1. 概论"></a><strong>1. 概论</strong></h3><blockquote>
<p>一笔画判定法则：<br>1.首先这个图是连通的。<br>2.每个点都与偶数线相关联。</p>
</blockquote>
]]></content>
      <categories>
        <category>技术笔记</category>
        <category>数学建模</category>
      </categories>
      <tags>
        <tag>数学建模</tag>
      </tags>
  </entry>
  <entry>
    <title>Unreal Engine 4 学习笔记</title>
    <url>/2020/04/29/Unreal%20Engine%204%20%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</url>
    <content><![CDATA[<h3 id="基础操作"><a href="#基础操作" class="headerlink" title="基础操作"></a>基础操作</h3><ul>
<li>右键加“W，A，S，D”进行镜头移动</li>
<li>选中物体按E进行旋转操作，按W进行位移操作，按R进行缩放操作</li>
<li>在世界大纲视图选中物体按F进行聚焦</li>
<li>按G开启/关闭开发者模式</li>
</ul>
]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Unreal Engine</category>
      </categories>
      <tags>
        <tag>Unreal Engine</tag>
      </tags>
  </entry>
  <entry>
    <title>利用tf.concat()与np.concatenate()来拼接向量</title>
    <url>/2020/04/23/%E5%88%A9%E7%94%A8tf.concat()%E4%B8%8Enp.concatenate%E6%9D%A5%E6%8B%BC%E6%8E%A5%E5%90%91%E9%87%8F/</url>
    <content><![CDATA[<p>tf.concat()用法展示</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tf.concat([tensor1, tensor2, tensor3,...], axis)</span><br><span class="line"><span class="comment"># 使用通式，其中tensor1等表示矩阵对象；axis表示拼接的维度，数值越大，纬度越高</span></span><br><span class="line"><span class="comment">#---------------------------------------------------------</span></span><br><span class="line">t1 = [[1, 2, 3], [4, 5, 6]]  t2 = [[7, 8, 9], [10, 11, 12]]  </span><br><span class="line">tf.concat([t1, t2], 0)  </span><br><span class="line"><span class="comment"># [out] : [[1, 2, 3], [4, 5, 6], [7, 8, 9], [10, 11, 12]]  </span></span><br><span class="line">tf.concat([t1, t2], 1)  </span><br><span class="line"><span class="comment"># [out] : [[1, 2, 3, 7, 8, 9], [4, 5, 6, 10, 11, 12]]   </span></span><br><span class="line"><span class="comment">#---------------------------------------------------------</span></span><br><span class="line"><span class="comment"># tensor t3 with shape [2, 3]  </span></span><br><span class="line"><span class="comment"># tensor t4 with shape [2, 3]  </span></span><br><span class="line">tf.shape(tf.concat([t3, t4], 0))  <span class="comment"># shape:[4, 3]  </span></span><br><span class="line">tf.shape(tf.concat([t3, t4], 1))  <span class="comment"># shape:[2, 6]</span></span><br></pre></td></tr></table></figure>
<p>简单来讲，对于形状如[[ ], [ ]]和[[ ], [ ]]的矩阵，低维拼接等于拿掉最外面括号，高维拼接是拿掉里面的括号(保证其他维度不变)。如果axis为负数（-num），则表示倒数第num维度。</p>
<hr>
<p>np.concatenate的用法与tf.concat()类似，所以下面只展示示例，不做过多介绍</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">z = np.array([[1, 2, 3, 4],[5, 6, 7, 8],[9, 10, 11, 12],[13, 14, 15, 16]])</span><br><span class="line">a = np.concatenate(z,axis=1)</span><br><span class="line">[out]:</span><br><span class="line">	a = [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 ]</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 基础语法</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>利用reshape重塑数组</title>
    <url>/2020/04/22/%E5%88%A9%E7%94%A8reshape%E9%87%8D%E5%A1%91numpy%E6%95%B0%E7%BB%84/</url>
    <content><![CDATA[<blockquote>
<p>在数据预处理阶段，我们经常需要重塑数组。这里所介绍的numpy内置属性reshape将有助于此</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">z = np.array([[1, 2, 3, 4],[5, 6, 7, 8],[9, 10, 11, 12],[13, 14, 15, 16]])</span><br><span class="line"><span class="comment"># 创建一个形状为（4，4）的数组[z]</span></span><br><span class="line">a = z.reshape(-1)</span><br><span class="line"><span class="comment"># 使用reshape重塑数组[z]</span></span><br><span class="line">[out]:</span><br><span class="line">	[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 ]</span><br><span class="line"><span class="comment">#----------------------------------------------------------</span></span><br><span class="line">a = z.reshape(-1,2)</span><br><span class="line"><span class="comment"># 在这种用法中，-1可以理解为数组行数待定，2表示重组后的数组列数为2</span></span><br><span class="line">[out]:</span><br><span class="line">	[[ 1  2]</span><br><span class="line">	 [ 3  4]</span><br><span class="line">	 [ 5  6]</span><br><span class="line">	 [ 7  8]</span><br><span class="line">	 [ 9 10]</span><br><span class="line">	 [11 12]</span><br><span class="line">	 [13 14]</span><br><span class="line">	 [15 16]]</span><br><span class="line"><span class="comment">#--------------------------------------------------------------</span></span><br><span class="line">a = z.reshape(2,2,4)</span><br><span class="line"><span class="comment"># 也可以指定行列，但重组后的矩阵元素数量必须与之前相同</span></span><br><span class="line">[out]:</span><br><span class="line">	[[[ 1  2  3  4]</span><br><span class="line">	  [ 5  6  7  8]]</span><br><span class="line"></span><br><span class="line">	 [[ 9 10 11 12]</span><br><span class="line">	  [13 14 15 16]]]</span><br></pre></td></tr></table></figure>
<blockquote>
<p>在TensorFlow中还可以利用tf.reshape对数组重塑</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">tf.reshape(tensor,shape,name=None)</span><br><span class="line"><span class="comment"># tensor表示要处理的对象，shape表示目标矩阵形状（如[num，num]）</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 基础语法</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>《数据结构与算法》笔记(Python语言实现)</title>
    <url>/2020/04/19/%E3%80%8A%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95%E3%80%8B%E7%AC%94%E8%AE%B0(Python%E8%AF%AD%E8%A8%80%E5%AE%9E%E7%8E%B0)/</url>
    <content><![CDATA[<h1 id="第一章-Python入门"><a href="#第一章-Python入门" class="headerlink" title="第一章 Python入门"></a>第一章 Python入门</h1><hr>
<h2 id="1-2-Python对象"><a href="#1-2-Python对象" class="headerlink" title="1.2 Python对象"></a>1.2 Python对象</h2><h3 id="1-2-1-标识符、对象和赋值语句"><a href="#1-2-1-标识符、对象和赋值语句" class="headerlink" title="1.2.1 标识符、对象和赋值语句"></a>1.2.1 标识符、对象和赋值语句</h3><blockquote>
<p>概念理解</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temperature = 98.6</span><br><span class="line"><span class="comment"># [temperature = 98.6] - 赋值语句</span></span><br><span class="line"><span class="comment"># temperature - 标识符</span></span><br><span class="line"><span class="comment"># 98.6 - 对象</span></span><br></pre></td></tr></table></figure>
<blockquote>
<p>标识符的引用原理</p>
</blockquote>
<ul>
<li>程序员可以向现有对象指定第二个标识符建立一个别名<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temperature = 98.6</span><br><span class="line">original = temperature</span><br><span class="line"><span class="comment"># 这里标识符[original]和标识符[temperature]都是对象[98.6]的别名</span></span><br></pre></td></tr></table></figure></li>
<li>一旦建立了别名，两个名称都可以用来访问底层对象。如果对象的一个别名被赋值语句重新赋予了新的值，那么这并不影响已存在的对象，而是给别名重新分配了存储对象<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">temperature = temperature +5.0</span><br><span class="line">original</span><br><span class="line"></span><br><span class="line">[out]:</span><br><span class="line">	temperature = 103.6</span><br><span class="line">	original = 98.6</span><br></pre></td></tr></table></figure>

</li>
</ul>
<a id="more"></a>

<h3 id="1-2-3-Python的内置类"><a href="#1-2-3-Python的内置类" class="headerlink" title="1.2.3 Python的内置类"></a>1.2.3 Python的内置类</h3><blockquote>
<p>浮点类</p>
</blockquote>
<ul>
<li>在转化字符型的数字时，建议使用<strong>float（而不是int）</strong>进行转换<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="built_in">float</span>(<span class="string">'3'</span>)</span><br><span class="line"></span><br><span class="line">[out]:</span><br><span class="line">	3.0</span><br><span class="line"><span class="comment">#------------------------</span></span><br><span class="line"><span class="built_in">float</span>(<span class="string">'3.14'</span>)</span><br><span class="line"></span><br><span class="line">[out]:</span><br><span class="line">	3.14</span><br></pre></td></tr></table></figure>
<blockquote>
<p>set类和frozenset类</p>
</blockquote>
</li>
<li>set类和frozenset类都属于<strong>集合类型</strong>（frozenset类是集合类型的一种不可变的形式）</li>
<li>集合内的元素是<strong>无序</strong>的且只有<strong>不可变类型</strong>的实例才可以被添加到集合中（所以frozenset类是可以添加进集合的）</li>
</ul>
<h2 id="1-3-表达式、运算符和优先级"><a href="#1-3-表达式、运算符和优先级" class="headerlink" title="1.3 表达式、运算符和优先级"></a>1.3 表达式、运算符和优先级</h2><blockquote>
<p>算术运算符</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">+ 加</span><br><span class="line">- 减</span><br><span class="line">* 乘</span><br><span class="line">/ 真正的除</span><br><span class="line">// 整数除法</span><br><span class="line">% 模运算符</span><br></pre></td></tr></table></figure>
<ul>
<li>Python严谨地扩展了//和%的语义。q=n//m和r=n%m，Python保证q*m+r=n<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">a = 27</span><br><span class="line">b = -4</span><br><span class="line">a % b <span class="comment"># a % b == -1 </span></span><br><span class="line">a//b <span class="comment"># a//b == -7</span></span><br><span class="line">(a//b)*(b)+(a % b)==a <span class="comment"># (-7)*(-4)+(-1)==27</span></span><br><span class="line"><span class="comment">#--------------------------</span></span><br><span class="line"><span class="comment">#  在浮点数运算也是这样，但又有点不一样</span></span><br><span class="line">a=8.2</span><br><span class="line">b=3.14</span><br><span class="line">a//b <span class="comment"># a//b == 2.0</span></span><br><span class="line">a%b <span class="comment"># a%b == 1.919999999999999</span></span><br><span class="line"><span class="comment"># 1.919999999999999==1.92 &gt;&gt; False</span></span><br><span class="line">(a//b)*b+(a%b)==a <span class="comment"># (a//b)*b+(a%b)==a &gt;&gt; True</span></span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>技术笔记</category>
        <category>《数据结构与算法》</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>数据结构与算法</tag>
      </tags>
  </entry>
  <entry>
    <title>Pandas在Python语言下的基础使用</title>
    <url>/2020/04/14/Pandas%E5%9C%A8Python%E8%AF%AD%E8%A8%80%E4%B8%8B%E7%9A%84%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8/</url>
    <content><![CDATA[<ul>
<li>Pandas是个强大的结构数据处理包，但依本人经验来看：<strong>强烈建议在保存Pandas的DataFrame数据时，最好转化为numpy数组文件（.npy）进行保存</strong></li>
</ul>
<p><em>从实际使用来看，如果将DataFrame数据保存为csv或txt文件，在重新加载数据文件时，数据类型会自动转换成str类型，带来不必要的麻烦</em></p>
<blockquote>
<p>以下是我在实际应用&lt;预测关键蛋白&gt;中的实例</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">proteins_interaction_name=list(proteins_interaction_relationship.keys()) </span><br><span class="line"><span class="comment"># 将蛋白质名称列表赋值给对象proteins_interaction_name</span></span><br><span class="line">a = [proteins_interaction_relationship,proteins_labels] </span><br><span class="line"><span class="comment"># proteins_interaction_relationship以及proteins_labelsd都是字典对象</span></span><br><span class="line">data_preprocessing = pd.DataFrame(a,index=[<span class="string">'Proteins_interaction_relationship'</span>,<span class="string">'proteins_labels'</span>]) </span><br><span class="line"><span class="comment"># 通过pd.DataFrame内置函数依照proteins_interaction_relationship以及proteins_labelsd字典对象构建Pandas的DataFrame</span></span><br><span class="line"><span class="comment"># index为pd.DataFrame的内置属性，用于给每行添加索引</span></span><br><span class="line">data_preprocessing = data_preprocessing.dropna(axis=1)  </span><br><span class="line"><span class="comment"># 通过[DataFrame](代指DataFrame类型对象).dropna内置函数删除含有空值的列（axis=0为行） </span></span><br><span class="line">data_preprocessing.loc[2]=proteins_interaction_name</span><br><span class="line"><span class="comment"># 通过[DataFrame].loc[num]将proteins_interaction_name列表插入到第（num+1）行</span></span><br><span class="line">data_preprocessing.to_numpy</span><br><span class="line"><span class="comment"># 将数据转化成numpy数组类型，这样在保存数据时可以避免很多麻烦</span></span><br><span class="line">np.save(<span class="string">'data_preprocessing_DataFrame.npy'</span>,data_preprocessing) <span class="comment"># 保存Pandas结构数据</span></span><br></pre></td></tr></table></figure>

<hr>
<blockquote>
<p>以下是读取csv时的一些值得注意的操作（不推荐保存为csv，但建议掌握以备不时之需）</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">a=pd.read_csv(<span class="string">'data_preprocessing_DataFrame(无索引).csv'</span>,header=None)</span><br><span class="line"><span class="comment"># 注意：如果无列索引，必须添加header=None，否则默认把第一行数据处理成列名导致缺失</span></span><br><span class="line">a.values</span><br><span class="line"><span class="comment"># 通过这个操作，可以将对象a重新转化为DataFrame数据结构&lt;注意：此时数据的类型已经全部转化为str类型&gt;</span></span><br><span class="line">data_preprocessing.to_csv(<span class="string">'data_preprocessing_DataFrame(无索引).csv'</span>,index=False,header=False) </span><br><span class="line"><span class="comment"># 只保存DataFrame的数据，index=False表示无行索引，header=False表示无列索引</span></span><br><span class="line">data_preprocessing.to_csv(<span class="string">'data_preprocessing_DataFrame.csv'</span>) </span><br><span class="line"><span class="comment"># 保存DataFrame的数据及索引</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 基础语法</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>《Python机器学习基础教程》笔记(scikit-learn框架)</title>
    <url>/2020/04/13/%E3%80%8APython%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80%E6%95%99%E7%A8%8B%E3%80%8B%E7%AC%94%E8%AE%B0(scikit-learn%E6%A1%86%E6%9E%B6)/</url>
    <content><![CDATA[<h1 id="第一章-引言"><a href="#第一章-引言" class="headerlink" title="第一章 引言"></a>第一章 引言</h1><hr>
<h2 id="1-7-第一个应用：鸢（yuan）尾花分类"><a href="#1-7-第一个应用：鸢（yuan）尾花分类" class="headerlink" title="1.7 第一个应用：鸢（yuan）尾花分类"></a>1.7 第一个应用：鸢（yuan）尾花分类</h2><h3 id="1-7-3-要事第一：观察数据"><a href="#1-7-3-要事第一：观察数据" class="headerlink" title="1.7.3 要事第一：观察数据"></a>1.7.3 要事第一：观察数据</h3><blockquote>
<p>在构建模型时，最重要的是要首先<strong>观察数据</strong>。<br>检查数据的最佳方法就是将其<strong>可视化</strong>。<br>当数据<strong>只有两个特征</strong>时，可以使用<strong>散点图</strong>。<br>当数据<strong>有多个特征</strong>时，解决这个问题的一种方法就是绘制<strong>散点图矩阵</strong>(pair plot)。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 以下为绘制散点图矩阵的示例程序</span></span><br><span class="line"><span class="comment"># scatter_matrix为pandas绘制散点图矩阵的函数,矩阵的对角线是每个特征的直方图</span></span><br><span class="line"><span class="comment"># 利用X_train中的数据创建DataFrame</span></span><br><span class="line"><span class="comment"># 利用iris_dataset.feature_names中的字符串对数据列进行标记</span></span><br><span class="line">iris_dataframe = pd.DataFrame(X_train, columns = iris_dataset.feature_names)</span><br><span class="line"><span class="comment"># 利用DataFrame创建散点图矩阵，按y_train着色</span></span><br><span class="line">grr = pd.scatter_matrix(iris_dataframe, c = y_train, figsize = (15,15), marker = <span class="string">'o'</span> ...)</span><br></pre></td></tr></table></figure>

<a id="more"></a>

<h3 id="1-7-4-构建第一个模型：k近邻算法"><a href="#1-7-4-构建第一个模型：k近邻算法" class="headerlink" title="1.7.4 构建第一个模型：k近邻算法"></a>1.7.4 构建第一个模型：k近邻算法</h3><blockquote>
<p>k近邻算法：算法会在训练集中寻找与这个新数据点A最近的任意k个邻居（这也是&lt;k近邻算法&gt;中’k’的含义），然后将找到的数据点的标签赋值给这个新数据点A。<br>scikit-learn中所有的机器学习模型都是在各自的被作为[Estimator]的类中完成的。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># k近邻算法是在neighbors模块的KNeighborsClassifier类中实现的</span></span><br><span class="line">from sklearn.neighbors import KNeighborsClassifier</span><br><span class="line">knn = KNeighborsClassifier(n_neighbors = 1)</span><br><span class="line"><span class="comment"># n_neighbors是KNeighborsClassifier最重要的参数，表示邻居的数目</span></span><br></pre></td></tr></table></figure>

<h3 id="1-7-5-做出预测"><a href="#1-7-5-做出预测" class="headerlink" title="1.7.5 做出预测"></a>1.7.5 做出预测</h3><blockquote>
<p>scikit-learn的输入数据必须是二维数组。</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 调用knn对象的predict方法来进行预测：</span></span><br><span class="line">prediction = knn.predict(X_new)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">"Prediction :"</span>.format(prediction))</span><br><span class="line"><span class="comment"># [out]:Prediction :[0](标签数据)</span></span><br></pre></td></tr></table></figure>
<hr>
<h1 id="第二章-监督学习"><a href="#第二章-监督学习" class="headerlink" title="第二章 监督学习"></a>第二章 监督学习</h1><hr>
<h2 id="2-1-分类与回归"><a href="#2-1-分类与回归" class="headerlink" title="2.1 分类与回归"></a>2.1 分类与回归</h2>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>《Python机器学习基础教程》</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>scikit-learn</tag>
      </tags>
  </entry>
  <entry>
    <title>python画散点图[plt.scatter()]以及矩阵散点图[pd.scatter_matrix()]详解（待优化）</title>
    <url>/2020/04/13/python%E7%94%BB%E6%95%A3%E7%82%B9%E5%9B%BE%5Bplt.scatter()%5D%E4%BB%A5%E5%8F%8A%E7%9F%A9%E9%98%B5%E6%95%A3%E7%82%B9%E5%9B%BE%5Bpd.scatter_matrix()%5D%E8%AF%A6%E8%A7%A3/</url>
    <content><![CDATA[<h1 id="plt-scatter-散点图"><a href="#plt-scatter-散点图" class="headerlink" title="plt.scatter() 散点图"></a>plt.scatter() 散点图</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">plt.scatter( x, y, s=20, c = None, marker = <span class="string">'o'</span>, cmap = none, norm = none, vmin = none, vmax = none, alpha = none, linewidths = none,</span><br><span class="line">	verts = none, edgecolors = none, hold = none,**kwargs)</span><br></pre></td></tr></table></figure>
<ul>
<li>s:散点的大小</li>
<li>c:散点的颜色，’r ‘/‘g’/‘y’/‘w’/‘k’…….</li>
<li>marker:散点形状,  ‘.’(点)/‘o’(圆)/‘v’(倒三角形)/‘ * ‘(星星)/‘s’(正方形)………</li>
<li>cmap：colormap，颜色版：’accent’,’blues’,’bugn’,’oranges’….</li>
<li>vmin，vmax:亮度设置，标亮</li>
<li>alpha ：颜色透明程度， 实数，0-1之间</li>
<li>linewidths:线的宽度</li>
<li>linestyle: 线的风格，’–’（虚线）/ ‘-‘ (直线) / ‘-.’(间隔虚线)/ ‘: ‘(全为点)</li>
</ul>
<hr>
<h1 id="pd-scatter-matrix-散点图"><a href="#pd-scatter-matrix-散点图" class="headerlink" title="pd.scatter_matrix()散点图"></a>pd.scatter_matrix()散点图</h1><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">scatter_matrix([frame], alpha=0.5, c, figsize=None, ax=None, diagonal=<span class="string">'hist'</span>, marker=<span class="string">'.'</span>, density_kwds=None, hist_kwds=None, </span><br><span class="line">	y range_padding=0.05, **kwds)</span><br></pre></td></tr></table></figure>
<ol>
<li>frame - pandas dataframe变量对象 </li>
<li>alpha -  图像透明度，一般取(0,1] </li>
<li>figsize - 以英寸为单位的图像大小，一般以元组 (width, height) 形式设置 </li>
<li>ax - 可选一般为none </li>
<li>diagonal - 必须且只能在{‘hist’, ‘kde’}中选择1个，’hist’表示直方图(Histogram plot),’kde’表示核密度估计(Kernel Density Estimation)；该参数是scatter_matrix函数的关键参数 </li>
<li>marker - Matplotlib可用的标记类型，如’.’，’,’，’o’等 </li>
<li>density_kwds - (other plotting keyword arguments，可选)，与kde相关的字典参数 </li>
<li>hist_kwds - 与hist相关的字典参数 </li>
<li>range_padding - (float, 可选)，图像在x轴、y轴原点附近的留白(padding)，该值越大，留白距离越大，图像远离坐标原点 </li>
<li>kwds - 与scatter_matrix函数本身相关的字典参数 </li>
<li>c - 颜色（可以用数字标签决定颜色）</li>
</ol>
]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 数据可视化</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>利用TensorFlow实现简单的机器学习</title>
    <url>/2020/04/10/%E5%88%A9%E7%94%A8TensorFlow%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
    <content><![CDATA[<blockquote>
<p>该框架原型请参见TensorFlow官方教程《<a href="https://tensorflow.google.cn/tutorials/keras/text_classification" target="_blank" rel="noopener">对预文本进行文本分类处理</a>》</p>
</blockquote>
<p><em>以下是我利用(访问官网请点击)<a href="https://tensorflow.google.cn/" target="_blank" rel="noopener">TensorFlow</a>构建&lt;预测关键蛋白&gt;算法框架时实际使用的源码</em></p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf</span><br><span class="line">from tensorflow import keras</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------- 加载蛋白质字典</span></span><br><span class="line">protein_dictionary_matrix = np.load(<span class="string">'&lt;文件路径&gt;'</span>) <span class="comment"># 字典数据示例:&#123;('A':1,2,3),('B':2,5)&#125;</span></span><br><span class="line"><span class="comment">#------------------------- 将蛋白质语句长度标准化</span></span><br><span class="line">protein_dictionary_matrix = tf.contrib.keras.preprocessing.sequence.pad_sequences</span><br><span class="line">(protein_dictionary_matrix,maxlen=None,padding=<span class="string">'post'</span>,truncating=<span class="string">'post'</span>,value = 0)</span><br><span class="line"><span class="comment"># 具体用法可参见文章《如何利用Python将数组长度标准化》</span></span><br><span class="line"><span class="comment">#-------------------------------加载蛋白质标签矩阵</span></span><br><span class="line">proteins_labels_num = np.load(<span class="string">'&lt;文件路径&gt;'</span>) </span><br><span class="line"></span><br><span class="line"><span class="comment">#-------------------------------构建模型</span></span><br><span class="line">proteins_size = len(proteins_labels_num)*len(protein_dictionary_matrix[1]) <span class="comment"># 蛋白质数量*标准矩阵长度</span></span><br><span class="line"></span><br><span class="line">model = keras.Sequential()</span><br><span class="line">model.add(keras.layers.Embedding(proteins_size, 16))</span><br><span class="line"><span class="comment"># 第一层是嵌入Embedding层。该层采用整数编码的词汇表，并查找每个词索引的嵌入向量(embedding vector)</span></span><br><span class="line"><span class="comment"># 这些向量是通过模型训练学习到的。向量向输出数组增加了一个维度。得到的维度为：(batch, sequence, embedding)。</span></span><br><span class="line">model.add(keras.layers.GlobalAveragePooling1D())</span><br><span class="line"><span class="comment"># GlobalAveragePooling1D 将通过对序列维度求平均值来为每个样本返回一个定长输出向量。这允许模型以尽可能最简单的方式处理变长输入。</span></span><br><span class="line">model.add(keras.layers.Dense(16, activation=<span class="string">'relu'</span>))</span><br><span class="line"><span class="comment"># 该定长输出向量通过一个有 16 个隐层单元的全连接（Dense）层传输。</span></span><br><span class="line">model.add(keras.layers.Dense(1, activation=<span class="string">'sigmoid'</span>))</span><br><span class="line"><span class="comment"># 最后一层与单个输出结点密集连接。使用 Sigmoid 激活函数，其函数值为介于0与1之间的浮点数，表示概率或置信度。</span></span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"><span class="comment">#------------------------------损失函数与优化器</span></span><br><span class="line"><span class="comment"># 一个模型需要损失函数和优化器来进行训练。由于这是一个二分类问题且模型输出概率值（一个使用 sigmoid 激活函数的单一单元层），</span></span><br><span class="line"><span class="comment"># 我们将使用 binary_crossentropy 损失函数。</span></span><br><span class="line"><span class="comment"># 这不是损失函数的唯一选择，例如，你还可以选择 mean_squared_error。</span></span><br><span class="line"><span class="comment"># 但是，一般来说binary_crossentropy更适合处理概率——它能够度量概率分布之间的“距离”，或者在我们的示例中，指的是度量 ground-truth 分布与预测值之间的“距离”。</span></span><br><span class="line">model.compile(optimizer=<span class="string">'adam'</span>,</span><br><span class="line">              loss=<span class="string">'binary_crossentropy'</span>,</span><br><span class="line">              metrics=[<span class="string">'accuracy'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment">#---------------------------------对数据进行切割处理</span></span><br><span class="line">x_val = protein_dictionary_matrix[:1000] <span class="comment"># 实验集</span></span><br><span class="line">partial_x_train = protein_dictionary_matrix[1000:] <span class="comment"># 验证集</span></span><br><span class="line"></span><br><span class="line">y_val = proteins_labels_num[:1000] <span class="comment"># 实验集</span></span><br><span class="line">partial_y_train = proteins_labels_num[1000:] <span class="comment"># 验证集</span></span><br><span class="line"><span class="comment">#---------------------------------训练模型</span></span><br><span class="line"><span class="built_in">history</span> = model.fit(partial_x_train,</span><br><span class="line">                    partial_y_train,</span><br><span class="line">                    epochs=10,			<span class="comment"># 迭代次数</span></span><br><span class="line">                    batch_size=300,		<span class="comment"># 每次迭代的批量大小</span></span><br><span class="line">                    validation_data=(x_val, y_val),</span><br><span class="line">                    verbose=1)</span><br><span class="line"><span class="comment">#---------------------------------------------------------------评估模型</span></span><br><span class="line"><span class="comment"># 将返回两个值。损失值&lt;loss&gt;（一个表示误差的数字，值越低越好）与准确率&lt;accuracy&gt;（值越高越好）</span></span><br><span class="line">results = model.evaluate(protein_dictionary_matrix,  proteins_labels_num, verbose=2)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(results)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 框架用法</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>关键蛋白预测</tag>
        <tag>TensorFlow</tag>
      </tags>
  </entry>
  <entry>
    <title>Python字典中利用setdefault()函数创建字典</title>
    <url>/2020/04/09/Python%E5%AD%97%E5%85%B8%E4%B8%AD%E5%88%A9%E7%94%A8setdefault()%E5%87%BD%E6%95%B0%E5%88%9B%E5%BB%BA%E5%AD%97%E5%85%B8/</url>
    <content><![CDATA[<blockquote>
<p>关于该函数实际用法，可以参考文章《利用zip解决Python中字典自动正序带来的关系数据错位问题》(可通过博客搜索功能快速查找)</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># Python字典中的setdefault()函数：如果键不存在于字典中，将会添加键并将值设为默认值。</span></span><br><span class="line">dict.setdefault(key, default=None)</span><br><span class="line"><span class="comment"># dict -- 代指字典变量</span></span><br><span class="line"><span class="comment"># key -- 查找的键值。</span></span><br><span class="line"><span class="comment"># default -- 键不存在时，设置的默认键值。None为空值</span></span><br><span class="line"><span class="comment"># 对于default，可以设置set()等空列表或集合用以规定值的存储方式</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 基础语法</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>利用zip解决Python中字典自动正序带来的关系数据错位问题</title>
    <url>/2020/04/09/%E5%88%A9%E7%94%A8zip%E8%A7%A3%E5%86%B3Python%E4%B8%AD%E5%AD%97%E5%85%B8%E8%87%AA%E5%8A%A8%E6%AD%A3%E5%BA%8F%E5%B8%A6%E6%9D%A5%E7%9A%84%E5%85%B3%E7%B3%BB%E6%95%B0%E6%8D%AE%E9%94%99%E4%BD%8D%E9%97%AE%E9%A2%98/</url>
    <content><![CDATA[<blockquote>
<p>本问题最初出现在构建蛋白质的关系字典中</p>
</blockquote>
<ul>
<li>由于在字典中，数据的排序是自动正序的（也可以理解为乱序），在一组关系数据列表中，<br>我们构建字典的方式往往是先提取一组数据构建字典的键，再提取另一组数据一一对应为键的值 。但是由于字典的键是乱序的，那么对应的值也必然是错误的。本方法就是为了解决这个问题。</li>
</ul>
<p><em>如果你对问题的描述仍有疑惑，下面的示例代码将有助于你的理解以及对你遇到的问题的解决</em><br><em>关于setdefault()函数的使用，可以参考文章《Python字典中setdefault()函数的用法》</em>(可通过博客搜索功能快速查找)</p>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 为帮助你理解程序，我们假设一组关系数据[A-a，B-b，C-c，D-d]</span></span><br><span class="line"><span class="comment"># 以上数据表明A与a之间存在关系，可以理解为A与a互为标签（事实上在本实例中也确实是这样处理的）</span></span><br><span class="line"></span><br><span class="line">proteins_interaction_relationship = &#123;&#125; </span><br><span class="line"><span class="comment"># 首先，我们创建一个空的字典proteins_interaction_relationship </span></span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------------------- 创建相互作用关系语句</span></span><br><span class="line"><span class="comment"># protein_name1表示列表[A B C D]</span></span><br><span class="line"><span class="comment"># protein_name11表示列表[a b c d]</span></span><br><span class="line"><span class="comment"># dictionaries是一个字典&#123;A:1,B:2,C:3,D:4,a:5,b:6,c:7,d:8&#125;,该变量对代码理解影响不大。</span></span><br><span class="line"><span class="comment"># 使用setdefault()，它可以使我们不用提前给字典输入键，即精简了代码，又减小了BUG发生的概率。</span></span><br><span class="line"><span class="comment"># setdefault().add中add表示向set()空集中添加元素</span></span><br><span class="line"><span class="keyword">for</span> i,j <span class="keyword">in</span> zip(protein_name1,protein_name11):</span><br><span class="line">    proteins_interaction_relationship.setdefault(i,<span class="built_in">set</span>()).add(dictionaries[j])</span><br><span class="line"><span class="comment"># 在for循环中使用zip可以同时提取同一行相互存在关系的两个元素，键的创建和键的赋值是同时进行的，避免了关系数据错位。</span></span><br><span class="line"><span class="keyword">for</span> i,j <span class="keyword">in</span> zip(protein_name11,protein_name1):</span><br><span class="line">    proteins_interaction_relationship.setdefault(i, <span class="built_in">set</span>()).add(dictionaries[j])</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 问题解决</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>关键蛋白预测</tag>
      </tags>
  </entry>
  <entry>
    <title>非负矩阵分解（NMF）的Matlab实现</title>
    <url>/2020/04/08/%E9%9D%9E%E8%B4%9F%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3%EF%BC%88NMF%EF%BC%89%E7%9A%84Matlab%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<blockquote>
<p>非负矩阵分解(Nonnegative Matrix Factorization),简称NMF,是由Lee和Seung于1999年在自然杂志上提出的一种矩阵分解</p>
</blockquote>
<ul>
<li>它使分解后的所有分量均为非负值(要求纯加性的描述)并且同时实现非线性的维数约减.</li>
<li>NMF已逐渐成为信号处理、生物医学工程、模式识别、计算机视觉和图像工程等研究领域中最受欢迎的多维数据处理工具之一.<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">V=double(imread(<span class="string">'图片名或路径'</span>));      </span><br><span class="line">imshow(mat2gray(V));</span><br><span class="line">V1=V(:,:,1);		<span class="comment"># 将图片的第一通道数值赋值给V1</span></span><br><span class="line">V2=V(:,:,2);		<span class="comment"># 将图片的第二通道数值赋值给V2</span></span><br><span class="line">V3=V(:,:,3);		<span class="comment"># 将图片的第三通道数值赋值给V3</span></span><br><span class="line"></span><br><span class="line">[i,u]=size(V1);		<span class="comment"># 将V1的行数赋值给i，列数赋值给u</span></span><br><span class="line">r=100;				<span class="comment"># 设置分解矩阵的秩</span></span><br><span class="line">W=rand(i,r);		<span class="comment"># 初始化WH，为非负数</span></span><br><span class="line">H=rand(r,u);		<span class="comment"># 初始化WH，为非负数</span></span><br><span class="line">maviter=600;		<span class="comment"># 最大迭代次数</span></span><br><span class="line">-----------------------------------------------------------------------------------</span><br><span class="line"><span class="comment"># 以下为非负矩阵算法公式，V2，V3同上处理，就不重复展示,以'...'代替</span></span><br><span class="line"><span class="keyword">for</span> iter=1:maviter</span><br><span class="line">    W=W.*((V1./(W*H))*H<span class="string">');           	</span></span><br><span class="line"><span class="string">    W=W./(ones(i,1)*sum(W));    </span></span><br><span class="line"><span class="string">    H=H.*(W'</span>*(V1./(W*H)));</span><br><span class="line">end</span><br><span class="line">V1=W*H;</span><br><span class="line">...</span><br><span class="line">-----------------------------------------------------------------------------------</span><br><span class="line"><span class="comment"># 以下程序用于重新拼接图形</span></span><br><span class="line">img_V(:,:,1)=V1(:,:);</span><br><span class="line">img_V(:,:,2)=V2(:,:);</span><br><span class="line">img_V(:,:,3)=V3(:,:);</span><br><span class="line">figure;</span><br><span class="line">imshow(mat2gray(img_V));</span><br></pre></td></tr></table></figure></li>
</ul>
]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Matlab 算法实现</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>Matlab</tag>
      </tags>
  </entry>
  <entry>
    <title>利用Python将数组长度标准化</title>
    <url>/2020/04/08/%E5%88%A9%E7%94%A8Python%E5%B0%86%E6%95%B0%E7%BB%84%E9%95%BF%E5%BA%A6%E6%A0%87%E5%87%86%E5%8C%96/</url>
    <content><![CDATA[<blockquote>
<p>本方法需要使用tensorflow包，请确认你已安装</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import tensorflow as tf  </span><br><span class="line">from tensorflow import keras</span><br><span class="line"></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"><span class="comment">#------------------------- 将蛋白质语句长度标准化</span></span><br><span class="line">protein_dictionary_matrix = np.load(<span class="string">'文件路径'</span>) <span class="comment"># 载入数组</span></span><br><span class="line"></span><br><span class="line">protein_dictionary_matrix = keras.preprocessing.sequence.pad_sequences[适用于tensorflow2.0]</span><br><span class="line">(protein_dictionary_matrix,maxlen=None,padding=<span class="string">'post'</span>,truncating=<span class="string">'post'</span>,value = 0)</span><br><span class="line"><span class="comment"># protein_dictionary_matrix:	所要标准化的变量</span></span><br><span class="line"><span class="comment"># maxlen=None:	标准化长度:，None表示以数组最大长度为准</span></span><br><span class="line"><span class="comment"># padding='post':	'pre'或'post'，确定当需要补0时，从起始还是结尾补</span></span><br><span class="line"><span class="comment"># truncating:	'pre'或'post'，确定当需要截断序列时，从起始还是结尾截断</span></span><br><span class="line"><span class="comment"># value:	浮点数，将在填充时嵌入此值,默认的填充值0</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 问题解决</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>Python如何读取Excel文件</title>
    <url>/2020/04/08/Python%E5%A6%82%E4%BD%95%E8%AF%BB%E5%8F%96Excel%E6%96%87%E4%BB%B6/</url>
    <content><![CDATA[<blockquote>
<p>首先需在Python下安装xlrd包</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">pip install  xlrd <span class="comment"># cmd窗口</span></span><br></pre></td></tr></table></figure>
<ul>
<li>python操作excel主要用到xlrd和xlwt这两个库，即xlrd是读excel，xlwt是写excel的库。<br>由于xlrd使用更为频繁，这里只简单介绍xlrd读取Excel文件的用法</li>
</ul>
<hr>
<blockquote>
<p>以下为语法介绍</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import xlrd <span class="comment"># 首先在Python程序中加载xlrd包</span></span><br><span class="line"></span><br><span class="line">data1 = xlrd.open_workbook(<span class="string">'数据文件路径'</span>) <span class="comment"># 首先加载文件，并赋值给一个变量</span></span><br><span class="line">*</span><br><span class="line">table1 = data1.sheets()[0] <span class="comment"># 通过索引顺序获取。从data1变量中提取数据，并保存在变量table1中。</span></span><br><span class="line">table1 = data.sheet_by_name(sheet_name) <span class="comment"># 通过名称获取</span></span><br><span class="line"><span class="comment">#以上两个函数都会返回一个xlrd.sheet.Sheet()对象</span></span><br><span class="line">*</span><br><span class="line">protein_name1 = table1.col_values(num) <span class="comment"># table1.col_values提取*列方向的数据为列表，num=第几列（0为第一列）</span></span><br><span class="line">protein_name1 = table1.row_values(num) <span class="comment"># table1.row_values提取*行方向的数据为列表，num=第几行（0为第一行）</span></span><br><span class="line">*</span><br><span class="line">nrows = table.nrows  <span class="comment"># 获取该sheet中的有效*行数</span></span><br><span class="line">ncols = table.ncols  <span class="comment"># 获取该sheet中的有效*列数</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 基础语法</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title>利用Python将数据可视化为无向图（图论）</title>
    <url>/2020/04/08/%E5%88%A9%E7%94%A8Python%E5%B0%86%E6%95%B0%E6%8D%AE%E5%8F%AF%E8%A7%86%E5%8C%96%E4%B8%BA%E6%97%A0%E5%90%91%E5%9B%BE%EF%BC%88%E5%9B%BE%E8%AE%BA%EF%BC%89/</url>
    <content><![CDATA[<blockquote>
<p>以下以绘制蛋白质相互作用矩阵为例</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">import xlrd </span><br><span class="line"><span class="comment"># 原文件为Excel文件，故需调用xlrd包</span></span><br><span class="line"><span class="comment"># 相关使用可查阅另一篇文章《Python如何读取Excel文件》</span></span><br><span class="line">import numpy as np</span><br><span class="line">import networkx as nx</span><br><span class="line">import matplotlib.pyplot as plt</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------- 加载数据</span></span><br><span class="line">data1 = xlrd.open_workbook(<span class="string">'（数据文件路径）'</span>)</span><br><span class="line">data2 = xlrd.open_workbook(<span class="string">'（数据文件路径）'</span>)</span><br><span class="line">table1 = data1.sheets()[0]</span><br><span class="line">table2 = data2.sheets()[0]</span><br><span class="line"></span><br><span class="line">protein_name1 = table1.col_values(0)</span><br><span class="line">protein_name2 = table2.col_values(0)</span><br><span class="line">protein_name11 = table1.col_values(1)</span><br><span class="line">protein_name22 = table2.col_values(1)</span><br><span class="line"><span class="comment">#--------------------------- 数据可视化 </span></span><br><span class="line">G = nx.Graph() <span class="comment"># 首先创建一个空的无向图</span></span><br><span class="line">G.add_edges_from(zip(protein_name1,protein_name11)) <span class="comment"># zip将两个数组合并打包为一个（个人理解）</span></span><br><span class="line">nx.draw(G, with_labels=True) <span class="comment"># with_labels，节点是否带有标签，默认为true</span></span><br><span class="line">plt.show() <span class="comment"># 绘制图形</span></span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Python 数据可视化</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>关键蛋白预测</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo如何创建草稿/私密文章</title>
    <url>/2020/04/08/Hexo%E5%A6%82%E4%BD%95%E5%88%9B%E5%BB%BA%E8%8D%89%E7%A8%BF%EF%BC%88%E7%A7%81%E5%AF%86%E6%96%87%E7%AB%A0%EF%BC%89/</url>
    <content><![CDATA[<ul>
<li>输入创建草稿命令，系统会在source/_drafts目录下生成一个new-draft.md文件。但是这个文件不被显示在页面上，链接也访问不到。也就是说如果你想把某一篇文章移除显示，又不舍得删除，可以把它移动到_drafts目录之中。相当于很多博客都有的“私密文章”功能。 </li>
</ul>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo new draft <span class="string">"new draft(File Name)"</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo如何插入本地图片</title>
    <url>/2020/04/07/Hexo%E5%A6%82%E4%BD%95%E6%8F%92%E5%85%A5%E6%9C%AC%E5%9C%B0%E5%9B%BE%E7%89%87/</url>
    <content><![CDATA[<ul>
<li>由于某种原因安装图片插件安装不上，故使用此方法</li>
</ul>
<figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">![你想输入的替代文字](xxxx&#x2F;图片名.jpg)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo写作语法</title>
    <url>/2020/04/07/Hexo%E5%86%99%E4%BD%9C%E8%AF%AD%E6%B3%95/</url>
    <content><![CDATA[<blockquote>
<p>以下是效果展示:</p>
</blockquote>
<h1 id="一级标题"><a href="#一级标题" class="headerlink" title="一级标题"></a>一级标题</h1><h2 id="二级标题"><a href="#二级标题" class="headerlink" title="二级标题"></a>二级标题</h2><h3 id="三级标题"><a href="#三级标题" class="headerlink" title="三级标题"></a>三级标题</h3><h4 id="四级标题"><a href="#四级标题" class="headerlink" title="四级标题"></a>四级标题</h4><h5 id="五级标题"><a href="#五级标题" class="headerlink" title="五级标题"></a>五级标题</h5><p><del>这是横线</del><br><strong>这是加粗</strong><br><em>这是斜体</em></p>
<ul>
<li>无序列表1</li>
<li>无序列表2</li>
</ul>
<ol>
<li>有序排列1</li>
<li>有序排列2<br><code>内嵌代码</code><figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">代码块</span><br></pre></td></tr></table></figure>
<blockquote>
<p>引用</p>
</blockquote>
<a id="more"></a>
</li>
</ol>
<hr>
<blockquote>
<p>以下为源代码:</p>
</blockquote>
<figure class="highlight bash"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 一级标题</span></span><br><span class="line"><span class="comment">## 二级标题</span></span><br><span class="line"><span class="comment">### 三级标题	</span></span><br><span class="line"><span class="comment">#### 四级标题</span></span><br><span class="line"><span class="comment">##### 五级标题</span></span><br><span class="line">~~这是横线~~	</span><br><span class="line">**这是加粗**	</span><br><span class="line">*这是斜体*</span><br><span class="line">* 无序列表1</span><br><span class="line">* 无序列表2</span><br><span class="line">1. 有序排列1</span><br><span class="line">2. 有序排列2</span><br><span class="line">`内嵌代码`</span><br><span class="line">` ` `  <span class="comment">#无间隔</span></span><br><span class="line">代码块</span><br><span class="line">` ` `  <span class="comment">#无间隔</span></span><br><span class="line">&gt;引用</span><br><span class="line">文章太长，截断按钮文字(在需要截断的行增加此标记：&lt;!--more--&gt;)</span><br></pre></td></tr></table></figure>]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
  <entry>
    <title>Hexo进行本地预览</title>
    <url>/2020/04/06/Hexo%E8%BF%9B%E8%A1%8C%E6%9C%AC%E5%9C%B0%E9%A2%84%E8%A7%88/</url>
    <content><![CDATA[<h2 id="使用-hexo-s-进行本地预览"><a href="#使用-hexo-s-进行本地预览" class="headerlink" title="使用 hexo s 进行本地预览"></a>使用 hexo s 进行本地预览</h2><figure class="highlight bash"><table><tr><td class="code"><pre><span class="line">$ hexo s</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>技术笔记</category>
        <category>Hexo</category>
      </categories>
      <tags>
        <tag>Hexo</tag>
      </tags>
  </entry>
</search>
